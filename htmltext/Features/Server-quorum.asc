(http://www.gluster.org/community/documentation/index.php/Planning34[Back
to 3.4 planning page]?)

Feature

Server-Quorum

1 Summary

This feature when enabled kills the bricks in the volume that do not
meet the quorum because of network splits/outages.

2 Owners

Pranith Kumar K Vijay Bellur Anand Avati

3 Current status

---------------------------------------------------
 Please follow the following bug for the updates:
 https://bugzilla.redhat.com/show_bug.cgi?id=839595
---------------------------------------------------

4 Detailed Description

----------------------------------------------------------------------------
 This quorum is on the server-side i.e. in glusterd. Whenever the glusterd
 on a machine observes that the quorum is not met, it brings down the bricks
 to prevent data split-brains. When the network connections are brought back
 up and the quorum is restored the bricks in the volume are brought back up.
 In glusterd commands to configure the quorum values are provided which are
 listed in the sections below. When the quorum is not met for a volume, any
 commands that update the volume configuration or peer addition or detach
 are not allowed.
 
----------------------------------------------------------------------------

5 Benefit to GlusterFS

--------------------------------------------------------------------
 This feature helps in avoiding split-brains in distributed systems.
--------------------------------------------------------------------

 +
 6. Scope

6.1. Nature of proposed change

-------------------------------------------------
  The feature is implemented as part of glusterd.
 
-------------------------------------------------

6.2. Implications on manageability

------------------------------------------------------------------------
  Gluserd has two more commands that are used to configure this feature.
------------------------------------------------------------------------

6.3. Implications on presentation layer

-------
  None.
-------

 +
 6.4. Implications on persistence layer

-------
  None.
-------

6.5. Implications on 'GlusterFS' backend

------
 None.
------

 +
 6.6. Modification to GlusterFS metadata

------
 None.
------

 +
 6.7. Implications on 'glusterd'

-----------------------------------------------------------------------------
Two new options are added to glusterd which can be modified using volume-set.
-----------------------------------------------------------------------------

volume set all is introduced to configure quorum ratio.

7 How To Test

------------------------------------------------------------------------------------------------------------------
 1) If the quorum options are not enabled, There should be no change in the glusterd functionality.
 2) Check if the volume set functionality for the following options is working fine.
 cluster.server-quorum-type - none/server
 cluster.server-quorum-ratio - this is % > 50. If the volume is not set with any ratio the equation for quorum is:
 active_peer_count > 50% of all peers in cluster. But when the percentage (P)
 is specified the equation for quorum is active_peer_count >= P % of all the
 befriended peers in cluster.
 3) Check if by default cluster.server-quorum-type is none for a volume.
 4) check if all-volume set/reset is working for cluster.server-quorum-ratio
 is working. This option is the only option allowed as an option for
 all-volumes.
 5) When quorum is disabled keep triggering network disconnections between
 peers and observe that the bricks are not going down or coming backup.
 6) When quorum is enabled keep triggering network disconnections between
 peers and observe that the bricks are going down or coming backup.
 7) When quorum is disabled keep bringing down just the glusterd processes
 and check that the bricks are not affected by this.
 8) When quorum is enabled keep bringing down just the glusterds the
 bricks will go down after quorum is not met.
 NOTE: glusterd not running and network connection between two machines
 is down are treated equally.
 9) Check that when the quorum is not met for any of the volume, the volume
 updates on the machine which does not meet quorum the updates are not allowed.
 10) Check that peer probe/deprobe are not allowed on the machine where
 the quorum is not met.
 11) Check that the bricks for a volume are not up until the quorum is met
 when the machine is rebooted if quorum on the volume is enabled.
 12) bricks should comeup as soon as glusterd comes up when quorum is disabled.
 13) Check glusterd volume/peer operations when the quorum status of peers
 is in the process of initializing.
 14) kill glusterd on one of the machines(lets call this M1) in cluster and
 keep killing glusterds on the machines until the quorum on M1 would be lost.
 Bring back the glusterd on M1. Bricks on M1 should not be running once the
 glusterd comes backup.
 15) kill glusterd and bring it back up bricks on the machine should not see
 any brick re-starts if the quorum is not enabled.
 16) Check that peer detach removes the peer when force option is given even
 when quorum is not met.
 17) Check the new store file /var/lib/glusterd/options is updated with the 
 volume set/reset all commands.
 18) Peer probe/deprobe should reflect all volume options.
 19) Check storing and restoring of all volume options.
 20) volume status should work fine even when quorum is not met.
 21) volume set/reset of quorum options should work fine even when the quorum
 is not met. This is to get the system out of locked-in state of quorum in
 desperate circumstances.
 NOTE: Please note that the % above is a floating point percentage.
------------------------------------------------------------------------------------------------------------------

8 User Experience

--------------------------------------------------------------------
 gluster volume set <volname> cluster.server-quorum-type none/server
 gluster volume set all cluster.server-quorum-ratio <percentage%>
--------------------------------------------------------------------

9 Dependencies

------
 None.
------

10 Documentation

--------------------------------
 <Documentation for the feature>
--------------------------------

11 Status

-----------
 Completed.
-----------

 +
 12 Comments and Discussion

--------------
 <Follow here>
--------------
