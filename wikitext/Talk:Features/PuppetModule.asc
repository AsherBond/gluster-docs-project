On this feature we have a few interested parties:

* semiosis
* thomasnomas
* purpleidea
* gregswift

[[]]
Scope
~~~~~

So what exactly is the scope of what this module will do? I've got a
basic work module done that deploys gluster on both the server and
client side. This was done against the 3.2 series. It has not been
updated for the changes in 3.3.

https://github.com/gregswift/puppet/tree/master/gluster

* johnmark response: please add your name to the feature template, as
well as a link to your github repo as a starting point. Another link was
posted yesterday from someone else working on this -
http://www.gluster.org/2012/07/a-puppet-module-for-gluster/ - I think
someone will need to step forward and define the best way to do this. Or
we just end up with multiple Puppet modules - not sure that's
necessarily a bad thing.

* purpleidea response: from the look of gregswift's module, we're aiming
for different goals at the moment. i plan to continue working on mine
for the moment. there are some excellent sysctl suggestions he's added
into his, which I'd like to incorporate into my module. I haven't looked
at the specifics, but this is the kind of magic that should be present.
The idea would be that you use puppet to setup gluster, and you've got
something working and optimized out of the box. I would love to have
some expert gluster dev commentary on some of these items, in
particular, sector size related things, relating to suggested hardware
raid config, filesystem config, and gluster block size config. If
someone would like to ping me on irc (purpleidea) I'd love to discuss.

* thomas@CERN: Being able to add node to a gluster , by defining a
parameter for each cluster (No master). Goal: replica-1 random nodes can
be down at any time. Magic should take care of knowing which node are
alive and able to add the new defined node. Discussion about puppetdb
role, zookeeper, etc... Managing volume is less important at the
beginning. Client: best practice to mount volume when you have a lot of
nodes and replica-1 can fail at the same time with fuse: dns
round-robin, other ? backupvolfile-server= as mount option can help ?

[[]]
bodepd

it actually looks like you guys are focused on 2 separate parts of the
same problem. gregswift on the best practices for installation of
gluster, purple idea on managing the actual creation of storage
clusters. There appears to be a pretty clean mapping between some of the
classes that you guys are working:

These look similar

*
https://github.com/gregswift/puppet/blob/master/gluster/manifests/init.pp
*
https://github.com/purpleidea/puppet-gluster/blob/master/manifests/client/base.pp

And these look similar:

*
https://github.com/gregswift/puppet/blob/master/gluster/manifests/server.pp
*
https://github.com/purpleidea/puppet-gluster/blob/master/manifests/server.pp

I would love to see at least an attempt to create a common solution to
solve both problems.

The best place to start could be to look at the differences between
those two files.

A few things to discuss are:

* what extra things exists in gregswift/../init.pp - does it make sense
to add those to purpleidea/../base.pp
* does it make sense to separate out the installation of the server in
purpleidea/../server.pp from the management of the firewalls and
configuration? Is this necessary for the two modules to be merged.

I am happy to help with any Puppet related questions during this
process. Feel free to ping me as bodepd freenode

[[]]
GitHub project, #2
~~~~~~~~~~~~~~~~~~

* https://github.com/purpleidea/puppet-gluster

[[]]
Another puppet module, by semiosis
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I just open-sourced & githubbed my puppet module for glusterfs. I've
been using this in production for over a year already. It's not as
feature rich as the others but it does some things nicely. feedback
welcome & always appreciated!

https://github.com/semiosis/puppet-gluster

[[]]
Yet another, from PuppetForge
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

http://forge.puppetlabs.com/thias/glusterfs
